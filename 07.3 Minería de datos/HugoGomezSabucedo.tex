\documentclass[a4paper,onecolumn]{extarticle}
\usepackage{geometry}
\usepackage[page,toc,titletoc,title]{appendix}
\usepackage{url}
\usepackage{caption}
\usepackage{subfigure}
\usepackage{subcaption}
\usepackage[sc]{mathpazo} % Use the Palatino font
\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\usepackage[utf8]{inputenc} % Use utf-8 as encoding
\linespread{1.05} % Line spacing - Palatino needs more space between lines
\usepackage{microtype} % Slightly tweak font spacing for aesthetics
\usepackage[spanish, activeacute]{babel}
 \decimalpoint
% \usepackage[hmarginratio=1:1,top=32mm,columnsep=20pt]{geometry} % Document marginshttps://www.overleaf.com/project/60211b96f72a79d4c7515e93
% \usepackage[hang, small,labelfont=bf,up,textfont=it,up]{caption} % Custom captions under/above floats in tables or figures
\usepackage{verbatim} % comentarios
\usepackage{listings}
\usepackage{xcolor}
\usepackage{wrapfig}
\lstset{
    inputencoding=utf8,
    frame=single,
    basicstyle=\fontsize{7}{10}\selectfont\ttfamily,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue}\bfseries,
    identifierstyle=\color{black},
    commentstyle=\color{gray}\itshape,
    stringstyle=\color{red},
    numbers=left,
    numberstyle=\tiny\color{gray},
    stepnumber=1,
    numbersep=10pt,
    showspaces=false,
    showstringspaces=false,
    breaklines=true,
    breakindent=0pt,
    breakatwhitespace=false,
    tabsize=2,
    captionpos=b,
    literate={á}{{\'a}}1
        {ã}{{\~a}}1
        {é}{{\'e}}1
        {ó}{{\'o}}1
        {í}{{\'i}}1
        {ñ}{{\~n}}1
        {¡}{{!`}}1
        {¿}{{?`}}1
        {ú}{{\'u}}1
        {Í}{{\'I}}1
        {Ó}{{\'O}}1
}
\setlength{\parskip}{0.8em}
\usepackage{natbib}
\usepackage{enumitem}
% \setlist[itemize]{noitemsep} % Make itemize lists more compact
% \usepackage{abstract} % Allows abstract customization
% \renewcommand{\abstractnamefont}{\normalfont\bfseries} % Set the "Abstract" text to bold
% \renewcommand{\abstracttextfont}{\normalfont\small\itshape} % Set the abstract itself to small italic text
\usepackage{titlesec}

\usepackage{fancyhdr} % Headers and footers
\pagestyle{fancy} % All pages have headers and footers
\fancyhead{}
\lhead{Hugo Gómez Sabucedo}
\rhead{Minería de datos y modelización predictiva}

\renewcommand{\footrulewidth}{0.2pt}
\usepackage{titling} % Customizing the title section
\usepackage[breaklinks=true]{hyperref} % For hyperlinks in the PDF
%\usepackage{array}
%\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\usepackage{graphicx}
%\usepackage{lipsum} % NO NECESARIO LUEGO
%\usepackage{amsmath}
%\usepackage{wrapfig}
%\usepackage{multicol}
%\usepackage{bm}


\let\stdsection\section
\renewcommand\section{\newpage\stdsection}

%-------------------------------------------------------------------------------
%	TITLE SECTION
%-------------------------------------------------------------------------------

\setlength{\droptitle}{-4\baselineskip} % Move the title up



\title{\begin{center} \Huge Minería de datos y modelización predictiva: Series Temporales\end{center}} % Article title
\author{
    \textsc{\Huge Hugo Gómez Sabucedo} \\ % Your name
    \large \href{mailto:hugogomezsabucedo@gmail.com}{hugogomezsabucedo@gmail.com} \\ [2ex] % Your email address
    \Large \textbf{Máster Big Data, Data Science \& Inteligencia Artificial} \\
    \normalsize Curso 2024-2025 \\
    \large Universidad Complutense de Madrid
}
\date{} % Leave empty to omit a date

\begin{document}
% Print the title
\maketitle
%\newpage
\tableofcontents
%\newpage
\begin{sloppypar}

%-------------------------------------------------------------------------
%	DOCUMENT
%-------------------------------------------------------------------------

\section{Introducción y análisis inicial} \label{introduccion}
\subsection{Introducción} \label{intro}
En este ejercicio se realizará el análisis y predicciones sobre una serie temporal, con datos obtenidos a partir del Instituto Nacional de Estadística. Estos 
datos, disponibles en el archivo \texttt{viajerosMD.xlsx}, que contienen los datos sobre los viajeros totales en ferrocarril de media distancia en España, 
medidos en \textbf{miles de viajeros}, desde el año 2010 hasta el 2024, medidos mensualmente. Aunque la serie original contiene datos que se remontan al año 2000, 
para no tener una serie tan grande, se ha decidido elegir únicamente estos datos. Por lo tanto, la serie constará de 15 años, o lo que es lo mismo, 180 
observaciones, de las cuales, en lo que se corresponde al punto 3 del enunciado de la práctica, reservaremos 12 para realizar el test de los modelos, siendo 
las 168 restantes los datos con los que entrenaremos el modelo.

El código completo de Python de esta práctica se adjunta en el archivo \texttt{codigoMineria3.py}, también al final de este documento, por lo que aquí sólo 
incluiremos \textit{snippets} de código que sean especialmente relevantes o que no se hayan visto en clase. Antes de comenzar con el análisis, debemos 
naturalmente importar el archivo en Python, y realizar una serie de pequeñas modificaciones. Estas consisten en transformar la fecha, para que sea un formato 
de fecha legible por Python. En el archivo original el formato es \textit{    2024M12}, por lo que empleamos el siguiente código para realizar la conversión 
(líneas 1 y 2). Además, transformamos los datos de la serie, los valores numéricos, para que se consideren como un número y no como string (línea 3), y se 
establece la fecha como índice (línea 4). Por último, debemos invertir la serie (línea 5), ya que el archivo ordena las observaciones desde la más reciente a 
la más antigua, y para su representación nos interesa tener en primer lugar la observación más antigua. Con esto, tendremos los datos listos y correctamente cargados.

\begin{lstlisting}[language=Python]
    viajeros['Fecha'] = viajeros['Fecha'].str.strip()
    viajeros['Fecha'] = pd.to_datetime(viajeros['Fecha'], format='%YM%m')
    viajeros['Viajeros'] = viajeros['Viajeros'].apply(pd.to_numeric, errors='coerce')
    viajeros.set_index('Fecha', inplace=True)
    viajeros = viajeros.iloc[::-1]
\end{lstlisting}

\subsection{Representación gráfica}
\begin{center}
    \begin{figure}[h!]
        \centering
        \includegraphics[width=\textwidth]{imgs/serie.png}
        \caption{} \label{fig:serie}
    \end{figure}
\end{center}
\begin{center}
    \begin{figure}[h!]
        \centering
        \includegraphics[width=\textwidth]{imgs/seriePorAño.png}
        \caption{} \label{fig:seriePorAño}
    \end{figure}
\end{center}
En la figura \ref{fig:serie}, nos encontramos con una representación tal cual de la serie, dónde se observa una clara estacionalidad en los datos, con valores 
que se repiten en periodos de un año. Además, se observa un brusco descenso en el año 2020, cuadrando con la pandemia, donde el número de viajes se redujo 
bruscamente, hasta llegar casi a 0, debido a las medidas que limitaban la movilidad. En el período post-pandemia, se observa una tendencia claramente al alza, 
que no dura sólo ese año, sino también hasta el presente, a la vez que se observa también una clara estacionalidad, pues si bien los viajeros aumentan cada año
que pasa, se sigue observando un pico en los datos a mediados de año, y un valle hacia finales de año. Esto se ve también en la figura \ref{fig:seriePorAño}, 
donde hemos descompuesto la serie asignando a cada año un color diferente, y hemos representado el número de viajeros en cada mes. Aquí se observa más 
claramente el escaso número de viajeros del año 2020, el ligero aumento que se produjo en 2021, y las cantidades tan elevadas de viajeros que vimos en los dos 
últimos años, así como un claro pico de viajeros que se produce en el mes de julio, seguido de una disminución brusca de los mismos en el mes de agosto, lo 
que se corresponde claramente con el patrón de vacaciones que estamos acostumbrados a ver en España.

\begin{center}
    \begin{figure}[h!]
        \centering
        \includegraphics[width=\textwidth]{imgs/descomposicion.png}
        \caption{} \label{fig:descomposicion}
    \end{figure}
\end{center}

Ya que la serie tiene un claro comportamiento estacional, podemos realizar su descomposición estacional, mediante el método \texttt{seasonal\_decompose}. Para 
hacer este método, podemos utilizar un modelo aditivo, en el que los valores desestacionalizados se obtienen sumando las correcciones estacionales a la serie;
o un modelo multiplicativo, donde la serie corregida se obtiene multiplicando la serie original por el componente estacional. Este último será el que usaremos, 
ya que en nuestros datos no tenemos ningún valor que sea 0. Si observamos la gráfica que se produce al realizar esta descomposición, en la figura 
\ref{fig:descomposicion}, vemos que el componente estacional (tercera gráfica) está claramente marcado, lo que quiere decir que la serie tiene un comportamiento 
estacional. Además, este toma valores alrededor de 1, ya que nos indica cuánto aumenta o disminuye el número de viajeros en un mes concreto con respecto a la 
media. En la cuarta gráfica, vemos el componente irregular, mientras que en la tercera observamos la tendencia, donde se ve claramente que la serie tenía una 
tendencia constante hasta que llegó la pandemia, donde se observa un brusco descenso, seguido de una marcada tendencia al alza.

\section{Modelos de suavizado exponencial} \label{suavizado}
En esta sección aplicaremos distintos modelos de suavizado, con el objetivo de determinar finalmente cuál de ellos es mejor. Estos modelos estiman los valores 
de los componentes de la serie en función del tiempo, usando los valores anteriores y suavizándolos empleando coeficientes que minimicen el error producido. 
Crearemos cuatro modelos diferentes partiendo de los datos de train, con el objetivo de realizar diferentes predicciones y compararlas con los datos de test, 
para evaluar que modelo es el que mejor se ajusta.

\subsection{Modelo de suavizado simple} \label{suavizadoSimple}
\begin{center}
    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.75\textwidth]{imgs/suavizadoSimple.png}
        \caption{Modelo de suavizado simple} \label{fig:suavizadoSimple}
    \end{figure}
\end{center}
El modelo de suavizado simple suele usarse cuando la serie no presenta una tendencia relevante, por lo que es casi seguro que podremos desestimarlo de entre 
los modelos candidatos a ser ganadores. Aún así, en la gráfica \ref{fig:suavizadoSimple} se muestra el resultado de la predicción para el último año de este 
modelo, donde se ve que claramente no es correcta, ya que muestra un valor fijo para las predicciones de los 12 meses ya que, como dijimos, este modelo sólo 
se usa para series que no tienen una tendencia muy marcada. Si vemos el parámetro alfa, este es de $0.523406$, mientras que el valor inicial es de $2465.023001$.

\subsection{Modelo de suavizado de Holt} \label{suavizadoHolt}
\begin{center}
    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.75\textwidth]{imgs/suavizadoHolt.png}
        \caption{Modelo de suavizado de Holt} \label{fig:suavizadoHolt}
    \end{figure}
\end{center}
El método de Holt es similar al anterior, pero en este caso presupone que la tendencia es lineal, es decir, que tiene una pendiente variable. De esta forma, 
en este método obtendremos dos parámetros, $\alpha$ y $\beta$, que se corresponden con el factor de suavización del nivel y la tendencia, respectivamente, así 
como el valor inicial de dicho nivel y tendencia. Si aplicamos el modelo y realizamos las predicciones, obtenemos la gráfica de \ref{fig:suavizadoHolt}, donde 
vemos que, aunque las predicciones siguen siendo totalmente erróneas, se aprecia la tendencia creciente que veíamos en los datos. En este caso, los parámetros 
que obtuvimos del modelo son $\alpha=0.547596$, $\beta=0.000100$, $L_{0}=2489.217917$ y $B_{0}=10.117447$.

\subsection{Modelo de tendencia amortiguada} \label{suavizadoAmortiguada}
\begin{center}
    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.75\textwidth]{imgs/suavizadoAmortiguada.png}
        \caption{Modelo de tendencia amortiguada} \label{fig:suavizadoAmortiguada}
    \end{figure}
\end{center}
El modelo o método de tendencia amortiguada es una variación del modelo ed Holt que acabamos de ver en \ref{suavizadoHolt}, que introduce un factor de 
amortiguación para que las predicciones no sean una simple recta, sino que tomen una forma ajustada más a una curva. Esto vendrá dado por el parámetro $\phi$ 
del modelo, que devuelve además los dos factores anteriores, así como los valores iniciales. Podemos ver las predicciones que ha realizado en la figura 
\ref{fig:suavizadoAmortiguada}. De esta forma, tenemos un $\alpha=0.521807$ y un $\beta=0.001862$, muy similares a los parámetros del anterior modelo, con un 
$L_{0}=2488.744544$ y $B_{0}=8.973355$, también similares a los anteriores. Sin embargo, si analizamos el $\phi$, vemos que es $\phi=0.990017$, prácticamente
1, lo cual indica que no tiene apenas efecto. Es decir, que el modelo de tendencia amortiguada nos producirá los mismos resultados casi que el modelo de Holt.
Esto podemos verlo fácilmente en la figura \ref{fig:suavizadoComp3}, donde comparamos las predicciones del modelo de suavizado simple, el de Holt y este de la 
tendencia amortiguada. En él, vemos en rojo las predicciones del modelo simple, que eran una simple línea sin pendiente, y tenemos en azul las predicciones 
del método de Holt, y en verde las del método de tendencias amortiguadas, donde vemos que ambas toman unos valores bastantes similares, estando la pendiente 
de este último modelo un poco menos pronunciada que la del anterior.
\begin{center}
    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.75\textwidth]{imgs/suavizadoComp3.png}
        \caption{Comparación: suavizado simple, Holt y \textit{damped}} \label{fig:suavizadoComp3}
    \end{figure}
\end{center}

\subsection{Modelo de suavizado de Holt-Winters} \label{suavizadoHoltWinters}
\begin{center}
    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.75\textwidth]{imgs/suavizadoHoltWinters.png}
        \caption{Modelo de tendencia amortiguada} \label{fig:suavizadoHoltWinters}
    \end{figure}
\end{center}
Por último, aplicaremos el modelo de suavizado de Holt-Winters, un modelo que a priori debería ser más adecuado, ya que incorpora la estacionalidad mediante un
coeficiente que multiplica a la tendencia. Los valores iniciales de la tendencia son estimados a partir de la media de los valores del primer ciclo; la pendiente 
se estima a partir de las diferencias en dos ciclos completos; y los índices estacionales, con los valores del primer periodo. En este caos, tenemos como 
parámetros los que se ven en la tabla \ref{tab:paramsHoltW}. Tenemos los parámetros de antes ($\alpha, \beta, L_{0} y B_{0}$), a los que se suma $\gamma$, que 
representa cuánto afecta la información nueva al patrón estacional; y los distintos parámetros iniciales de los factores estacionales $S_{0}$ a $S_{11}$, que,
ya que empleamos un modelo multiplicativo, nos indica cuánto se desvía ese mes en concreto de la media, ya sea con más viajeros (mayor que 1) o menos viajeros.
\begin{table}[]
    \begin{center}
        \begin{tabular}{|c|c|c|}
            \hline
            \textbf{Parámetro} & \textbf{Abreviatura} & \textbf{Valor} \\
            \hline
            smoothing\_level    & $\alpha$ & 0.464643 \\
            smoothing\_trend    & $\beta$ & 0.0244549 \\
            smoothing\_seasonal & $\gamma$ & 0.178452 \\
            initial\_level      & $L_{0}$ & 2650.66 \\
            initial\_trend      & $B_{0}$ & 1.00441 \\
            initial\_seasons.0  & $S_{0}$ & 0.894502 \\
            initial\_seasons.1  & $S_{1}$ & 0.931432 \\
            initial\_seasons.2  & $S_{2}$ & 1.03039 \\
            initial\_seasons.3  & $S_{3}$ & 1.06354 \\
            initial\_seasons.4  & $S_{4}$ & 1.10814 \\
            initial\_seasons.5  & $S_{5}$ & 1.02364 \\
            initial\_seasons.6  & $S_{6}$ & 1.15761 \\
            initial\_seasons.7  & $S_{7}$ & 0.974111 \\
            initial\_seasons.8  & $S_{8}$ & 1.1079 \\
            initial\_seasons.9  & $S_{9}$ & 1.1417 \\
            initial\_seasons.10 & $S_{10}$ & 1.05023 \\
            initial\_seasons.11 & $S_{11}$ & 0.930051 \\
            \hline
        \end{tabular}
        \caption{Parámetros del modelo de Holt-Winters}
        \label{tab:paramsHoltW}
    \end{center}
\end{table}

Está claro que este es el modelo de suavizado más adecuado, ya que, como se ve en la figura \ref{fig:suavizadoHoltWinters}, las predicciones se ajustan casi 
perfectamente con los datos que teníamos de test, sólo se observa que, para los últimos meses de 2024, no percibe a la perfección la disminución de viajeros
del mes de septiembre, y obtiene unos valores más elevados. 

En la tabla \ref{tab:prediccionesHoltWinter}, podemos ver, por una parte, la predicción que ha 
realizado este modelo y por otro, los resultados que teníamos reservados de los datos de test. Vemos que las diferencias, salvo en estos últimos meses que 
comentamos, donde son de 2500 miles de viajeros que ha estimado de más en el mes de septiembre, o 2000 miles de viajeros de más en diciembre, en el resto de 
meses la estimación se ajusta bastante a la realidad.

Como es evidente, no va a ser una predicción exacta, ni mucho menos, porque tampoco es lo que busca 
este método, pero sí que se corresponde de una forma bastante fiel a los datos que se han observado, teniendo en cuenta también que los datos presentan una 
tendencia creciente que es siempre más difícil de predecir. 
\begin{table}[h!]
    \begin{center}
        \begin{tabular}{|c|c|c|}
            \hline
            \textbf{Mes} & \textbf{Predicción} & \textbf{Datos test} \\
            \hline
            Enero 2024         & 3857.368419 & 3654 \\
            Febrero 2024       & 4220.702156 & 4020 \\
            Marzo 2024         & 4860.868766 & 4108 \\
            Abril 2024         & 4663.238474 & 4337 \\
            Mayo 2024          & 4850.431828 & 4983 \\
            Junio 2024         & 4878.574812 & 4341 \\
            Julio 2024         & 5899.436039 & 6588 \\
            Agosto 2024        & 5077.671698 & 4242 \\
            Septiembre 2024    & 6741.756478 & 4156 \\
            Octubre 2024       & 6124.685444 & 5103 \\
            Noviembre 2024     & 5562.474281 & 4766 \\
            Diciembre 2024     & 5501.244563 & 3460 \\
            \hline
        \end{tabular}
        \caption{Predicciones del modelo de Holt-Winters}
        \label{tab:prediccionesHoltWinter}
    \end{center}
\end{table}

\section{Modelos ARIMA}
En esta sección crearemos, por una parte, un modelo ARIMA de forma manual, ajustando los parámetros en base a lo observado en los correlogramas; y por otra 
parte, un modelo ARIMA de forma automática, empleando las funciones proporcionadas en Python.

\subsection{Autocorrelogramas y modelo ARIMA manual}\label{ARIMAman}
Para decidir que modelo ARIMA ajustaremos, primero vamos a analizar los autocorrelogramas, analizando la función de autocorrelación simple (ACF) y la función 
de autocorrelación parcial (PACF). La primera, la ACF, mide la correlación entre la serie y sus valores pasados, y se usa para identificar si la serie sigue un  
modelo MA o de medias móviles. De esta forma, una disminución lenta de la misma nos indicaría que la serie no es estacionaria. La segunda función, la PACF, se 
utiliza para identificar si la serie sigue un modelo AR o autoregresivo, ya que representa la relación de la serie entre el valor k y el actual, pero omitiendo 
el efecto de los valores intermedios entre k-1 y el actual. Así, los valores iniciales serán elevados, y el momento en que se corte será el orden del modelo.
\begin{center}
    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.75\textwidth]{imgs/correlogramas.png}
        \caption{Autocorrelogramas} \label{fig:autocorrelogramas}
    \end{figure}
\end{center}
En nuestro caso, si analizamos el ACF, vemos que decrece lentamente, lo que nos indica que la serie no es estacionaria y que requeriría diferenciación (es decir, 
un $d>0$). Respecto al PACF, vemos un descenso brusco en el primer retardo, mientras que a partir del segundo se puede considerar que es 0, por lo que nos sugiere
un modelo \texttt{AR(1)}. Sin embargo, como hemos visto que el ACF desciende lentamente, esto nos sugería que es necesario diferenciar la serie. Esto lo haremos
con el siguiente código:
\begin{lstlisting}[language=Python]
    diferencias = train.diff().dropna()
\end{lstlisting}
\begin{center}
    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.75\textwidth]{imgs/diferenciada.png}
        \caption{Diferenciación de la serie} \label{fig:diferenciacion}
    \end{figure}
\end{center}
En la figura \ref{fig:diferenciacion} vemos la diferenciación que acabamos de hacer, donde ya se ve que la serie tiene una media constante. Vamos a analizar de 
nuevo el ACF y el PACF, para determinar los parámetros del modelo, en la figura \ref{fig:autocorrelogramasDif}. En este caso, vemos que la serie tiene ya un 
comportamiento estacionario, ya que cae rápidamente tras el primer retardo, mientras que los valores de la PACF son casi todos 0, por lo que podemos concluir 
que la diferenciacón ha sido efectiva. Esto nos dice que es un proceso integrado de orden $d=1$.
\begin{center}
    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.75\textwidth]{imgs/correlogramasDif.png}
        \caption{Autocorrelogramas de la serie diferenciada} \label{fig:autocorrelogramasDif}
    \end{figure}
\end{center}

Por lo tanto, para elegir el modelo, aplicaremos la metodología Box-Jenkins, que se resume en cuatro etapas:
\begin{enumerate}
    \item Identificar el modelo.
    \item Estimar los parámetros.
    \item Probar el modelo.
    \item Realizar predicciones.
\end{enumerate}

Para estimar el modelo, se emplean los resultados de los ACF y los PACF, para crear el modelo $ARIMA(p,q,d)(P,Q,D)s$. Tenemos que tener en cuenta, también, que 
hemos tenido que realizar una diferenciación para hacer que la serie fuese estacionaria, lo cual nos implica un $d=1$, y se observó un comportamiento estacional 
en el mismo, por lo que $D=1$. De los gráficos de la ACF y la PACF deducimos que p y q deberían ser 1. Por lo tanto, se selecciona un modelo 
\texttt{ARIMA$(1,1,1)(0,1,1)_{12}$}. Ajustamos el modelo en Python mediante el siguiente código. 
\begin{lstlisting}[language=Python]
    modelo_arima = sm.tsa.ARIMA(train, order=(1, 1, 1), seasonal_order=(0, 1, 1, 12))
    resultados = modelo_arima.fit()
    print(resultados.summary())
\end{lstlisting}
Sin embargo, al analizar los parámetros, se ve que, si bien el modelo captura bien la dinámica de la serie, los residuos no son normales, y tenemos un p-valor 
para el AR(1) de $0.575$, lo que nos indica que este coeficiente no es significativo. Respecto a los residuos, vemos que el test de Jarque-Bera, que nos permite 
comprobar si los datos siguen la asimetría y curtosis de una normal, tiene un p-valor de 0, menor que 0.05, por lo que se rechaza la hipótesis de la normalidad. 
Además, tenemos un AIC de 2293.991, un BIC de 2306.164 y un HQIC de 2298.935, lo que nos indica un modelo bueno, pero ligeramente complejo. Vamos a ajustar, por 
tanto, otro modelo, eliminando el parámetro AR(1), haciendo un \texttt{ARIMA$(0,1,1)(0,1,1)_{12}$}.
\begin{center}
    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.85\textwidth]{imgs/residuos_arima.png}
        \caption{Estudio de los residuos del modelo ARIMA} \label{fig:residuos_arima}
    \end{figure}
\end{center}
En este modelo, tenemos los parámetros que se ven en la figura \ref{fig:parametrosArima}, que se estiman mediante máxima verosimilitud. Como todos los p-valores 
son menores que 0.05, podemos concluir que, ahora sí, todos son estadísticamente significativos, y se incluyen en el modelo. Por otra parte, en el gráfico 
\ref{fig:residuos_arima}, donde analizamos los residuos, vemos que, no muestran un patrón, se ajustan más o menos a la normal (aunque con una ligera asimetría), 
son incorrelados (pues están dentro de las bandas de confianza), y se observan algunas desviaciones en el gráfico Q-Q, que se deben con toda seguridad al año 
de la pandemia. Respecto a las métricas de ajuste, el AIC es de 2292.115, el BIC es de 2301.246 y el HQIC es de 2295.824, todos menores que en el anterior modelo, 
lo que nos indica que es mejor en términos de parsimonia y de ajuste. Es decir, es un modelo más sencillo, y que ajusta mejor. Si analizamos también el contraste 
de Ljung-Box, este toma un valor de 0.02 con una probabilidad de 0.90. Ya que la probabilidad es alta, mayor que 0.05, esto nos indica que los residuos son 
independientes (es decir, ruido blanco) y, por tanto, que el modelo es adecuado.
\begin{center}
    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.75\textwidth]{imgs/parametrosArima.png}
        \caption{Parámetros del modelo ARIMA} \label{fig:parametrosArima}
    \end{figure}
\end{center}

\subsection{Modelo autoARIMA}\label{autoARIMA}
Ahora ajustaremos el modelo automático, lo cual haremos mediante el siguiente comando:
\begin{lstlisting}[language=Python]
    modelo_auto = pm.auto_arima(train, m=12, d=0, D=1, start_p=0, max_p=3, start_q=0, max_q=3,seasonal=True, trace=True,error_action='ignore', suppress_warnings=True,stepwise=True) 
\end{lstlisting}
Esto nos proporciona el siguiente output:
\begin{lstlisting}[numbers=none]
    Performing stepwise search to minimize aic
    ARIMA(0,0,0)(1,1,1)[12] intercept   : AIC=2532.302, Time=0.16 sec
    ARIMA(0,0,0)(0,1,0)[12] intercept   : AIC=2529.758, Time=0.02 sec
    ARIMA(1,0,0)(1,1,0)[12] intercept   : AIC=2326.242, Time=0.29 sec
    ARIMA(0,0,1)(0,1,1)[12] intercept   : AIC=2430.942, Time=0.32 sec
    ARIMA(0,0,0)(0,1,0)[12]             : AIC=2531.202, Time=0.02 sec
    ARIMA(1,0,0)(0,1,0)[12] intercept   : AIC=2330.791, Time=0.12 sec
    ARIMA(1,0,0)(2,1,0)[12] intercept   : AIC=2327.524, Time=0.78 sec
    ARIMA(1,0,0)(1,1,1)[12] intercept   : AIC=2323.603, Time=0.62 sec
    ARIMA(1,0,0)(0,1,1)[12] intercept   : AIC=2324.114, Time=0.41 sec
    ARIMA(1,0,0)(2,1,1)[12] intercept   : AIC=2325.603, Time=1.15 sec
    ARIMA(1,0,0)(1,1,2)[12] intercept   : AIC=2325.603, Time=1.19 sec
    ARIMA(1,0,0)(0,1,2)[12] intercept   : AIC=2324.340, Time=0.99 sec
    ARIMA(1,0,0)(2,1,2)[12] intercept   : AIC=2326.882, Time=1.45 sec
    ARIMA(2,0,0)(1,1,1)[12] intercept   : AIC=2316.942, Time=0.81 sec
    ARIMA(2,0,0)(0,1,1)[12] intercept   : AIC=2317.061, Time=0.56 sec
    ARIMA(2,0,0)(1,1,0)[12] intercept   : AIC=2323.214, Time=0.35 sec
    ARIMA(2,0,0)(2,1,1)[12] intercept   : AIC=2318.875, Time=1.30 sec
    ARIMA(2,0,0)(1,1,2)[12] intercept   : AIC=2318.933, Time=1.34 sec
    ARIMA(2,0,0)(0,1,0)[12] intercept   : AIC=2330.780, Time=0.12 sec
    ARIMA(2,0,0)(0,1,2)[12] intercept   : AIC=2317.058, Time=1.02 sec
    ARIMA(2,0,0)(2,1,0)[12] intercept   : AIC=2322.958, Time=0.75 sec
    ARIMA(2,0,0)(2,1,2)[12] intercept   : AIC=inf, Time=1.71 sec
    ARIMA(3,0,0)(1,1,1)[12] intercept   : AIC=2318.228, Time=1.01 sec
    ARIMA(2,0,1)(1,1,1)[12] intercept   : AIC=2318.370, Time=1.01 sec
    ARIMA(1,0,1)(1,1,1)[12] intercept   : AIC=2316.413, Time=0.72 sec
    ARIMA(1,0,1)(0,1,1)[12] intercept   : AIC=2316.201, Time=0.58 sec
    ARIMA(1,0,1)(0,1,0)[12] intercept   : AIC=2331.178, Time=0.05 sec
    ARIMA(1,0,1)(0,1,2)[12] intercept   : AIC=2316.479, Time=1.48 sec
    ARIMA(1,0,1)(1,1,0)[12] intercept   : AIC=2323.333, Time=0.36 sec
    ARIMA(1,0,1)(1,1,2)[12] intercept   : AIC=2318.390, Time=1.37 sec
    ARIMA(2,0,1)(0,1,1)[12] intercept   : AIC=2318.191, Time=0.87 sec
    ARIMA(1,0,2)(0,1,1)[12] intercept   : AIC=2318.191, Time=0.84 sec
    ARIMA(0,0,0)(0,1,1)[12] intercept   : AIC=2530.616, Time=0.09 sec
    ARIMA(0,0,2)(0,1,1)[12] intercept   : AIC=2388.834, Time=0.64 sec
    ARIMA(2,0,2)(0,1,1)[12] intercept   : AIC=inf, Time=1.00 sec
    ARIMA(1,0,1)(0,1,1)[12]             : AIC=2314.686, Time=0.38 sec
    ARIMA(1,0,1)(0,1,0)[12]             : AIC=2329.101, Time=0.04 sec
    ARIMA(1,0,1)(1,1,1)[12]             : AIC=2315.315, Time=0.48 sec
    ARIMA(1,0,1)(0,1,2)[12]             : AIC=2315.310, Time=0.77 sec
    ARIMA(1,0,1)(1,1,0)[12]             : AIC=2321.435, Time=0.18 sec
    ARIMA(1,0,1)(1,1,2)[12]             : AIC=2317.277, Time=1.15 sec
    ARIMA(0,0,1)(0,1,1)[12]             : AIC=2431.070, Time=0.21 sec
    ARIMA(1,0,0)(0,1,1)[12]             : AIC=2322.608, Time=0.26 sec
    ARIMA(2,0,1)(0,1,1)[12]             : AIC=2316.682, Time=0.47 sec
    ARIMA(1,0,2)(0,1,1)[12]             : AIC=2316.683, Time=0.46 sec
    ARIMA(0,0,0)(0,1,1)[12]             : AIC=2531.484, Time=0.14 sec
    ARIMA(0,0,2)(0,1,1)[12]             : AIC=2388.587, Time=0.42 sec
    ARIMA(2,0,0)(0,1,1)[12]             : AIC=2315.577, Time=0.36 sec
    ARIMA(2,0,2)(0,1,1)[12]             : AIC=2317.649, Time=0.89 sec
   
   Best model:  ARIMA(1,0,1)(0,1,1)[12]          
   Total fit time: 31.727 seconds
\end{lstlisting}
De esta forma, el método autoARIMA ha determinado que el mejor modelo es un \texttt{ARIMA$(1,0,1)(0,1,1)_{12}$}, el cual es ligeramente parecido al que habíamos 
probado nosotros en el método manual, tanto el primero como el segundo. Sus parámetros están en la figura \ref{fig:parametros_autoArima}. De nuevo, todos los 
parámetros son significativos, puesto que su p-valor es 0. Además, en la figura \label{fig:residuos_auto} vemos el análisis de los residuos, que son prácticamente 
iguales a los del modelo manual. Obtenemos también una probabilidad alta en la prueba de Ljunb-Box, por lo que los residuos son ruido blanco, y podemos concluir 
que el modelo es también adecuado.
\begin{center}
    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.75\textwidth]{imgs/parametros_autoArima.png}
        \caption{Parámetros del modelo autoARIMA} \label{fig:parametros_autoArima}
    \end{figure}
\end{center}
\begin{center}
    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.85\textwidth]{imgs/residuos_auto.png}
        \caption{Estudio de los residuos del modelo autoARIMA} \label{fig:residuos_auto}
    \end{figure}
\end{center}

\subsection{Comparación y conclusiones}\label{compConcl}
Para determinar el mejor modelo, tenemos que analizar los resultados del \hyperref[modelo manual]{ARIMAman} y del \hyperref[modelo automático]{autoARIMA} (ya que 
está claro que los modelos de suavizado no van a ser los mejores, ya que vimos que no ajustaban bien los datos [exceptuando el de Holt-Winters, que en cualquier 
caso tiene peor ajuste que los modelos que venimos de analizar con el modelado de ARIMA]). Para determinar el mejor modelo, realizaremos una comparación basada 
en los parámetros de ambos, que recordamos que eran un \texttt{ARIMA$(0,1,1)(0,1,1)_{12}$} en el manual y un \texttt{ARIMA$(1,0,1)(0,1,1)_{12}$} en el 
automático. Si vemos los valores de AIC, tenemos 2292.115 para el manual y 2314.686 para el automático; para el BIC, 2301.246 para el manual y 2326.886 para 
el automático; y para el HQIC, 2295.824 para el manual y 2319.641 para el automático. Aunque la diferencia no es elevada, los tres valores son más bajos en el 
caso del manual, lo que nos sugiere que este podría ser el mejor modelo. Además, los parámetros en ambos modelos son estadísticamente significativos, ya que 
su p-valor es menor que 0.05. Sin embargo, en el modelo automático, el coeficiente del término autorregresivo AR(1) es de 0.94, muy próximo a 1, lo que podría 
sugerir que el modelo está captando una tendencia en vez de una dependencia temporal. La prueba de Ljung-Box es satisfactoria en ambos casos, al igual que la 
de Jarque-Bera; esta última, sin embargo, es mejor en el caso del modelo manual, ya que indica que se ajusta mejor a una distribución normal. Por lo tanto, y 
basándonos en todo esto, determinamos que el modelo manual es el mejor de entre los dos.

La expresión algebraica del modelo es, por tanto, la siguiente:
\begin{equation}
(1 - B)y_t = (1 + 0.3774B)(1+0.6293B^{12})e_t
\end{equation}
Donde el término $(1 - B)y_t$ es la diferencia de primer orden de la serie; $(1 + 0.3774B)$ es la parte de la media móvil no estacional, y $(1+0.6293B^{12})$ 
la parte de la media móvil estacional.

Calculamos las predicciones para este modelo manual, empleando para ello el método \texttt{get\_forecast}, para el año 2024 (que es el que reservamos para los 
datos de test), y graficamos tanto la predicción del número de viajeros como los datos de test que teníamos, para compararlos. En la figura \ref{fig:prediccionesManual} 
vemos estas predicciones en la serie global, con todos los datos, mientras que en la figura \ref{fig:prediccionesManualConf} vemos también los intervalos de 
confianza, representados de forma gráfica, como se solicitaba en el enunciado del trabajo. Como podemos ver, las predicciones realizadas se ajustan bastante 
bien a los datos de test que teníamos. En los primeros meses del año capta los resultados y las tendencias bastante bien, detectando también el pico de viajeros 
del mes de julio. Si bien es cierto que, por ejemplo, el descenso de viajeros de septiembre o diciembre no los captura tan bien. Sin embargo, es importante 
fijarse en un hecho curioso: los datos de test tienen tres meses con datos que sobresalen de los intervalos de confianza, lo cual puede significar que, aunque 
el modelo se ajuste bien, se han producido unas variaciones atípicas en los números de viajeros en estos meses, que el modelo no sería capaz de detectar. 
\begin{center}
    \begin{figure}[h!]
        \centering
        \begin{minipage}{0.45\textwidth}
            \centering
            \includegraphics[width=\textwidth]{imgs/predicciones_manual.png}
            \caption{Predicciones del modelo manual}
            \label{fig:prediccionesManual}
        \end{minipage}
        \hspace{0.005\textwidth} % Espacio entre las imágenes
        \begin{minipage}{0.5\textwidth}
            \centering
            \includegraphics[width=\textwidth]{imgs/predicciones_manual_conf.png}
            \caption{Predicciones del modelo manual con intervalos de confianza}
            \label{fig:prediccionesManualConf}
        \end{minipage}
    \end{figure}
\end{center}

Sin embargo, en resumen, podemos decir que el modelo es de una calidad bastante aceptable. Hemos representado, en la figura \ref{fig:predicciones_futuro} una 
predicción a mayores, para los próximos 5 años (72 meses, ya que tenemos que contar los 12 meses del año 2024). Estas predicciones captan, además de la 
estacionalidad de los datos, la tendencia al alza que vinimos comentando que se observaba desde la pandemia. Con estas predicciones será interesante analizar, 
una vez que se tengan los datos de este periodo, compararlos, para ver si el modelo realizó unas predicciones adecuadas.
\begin{center}
    \begin{figure}[h!]
        \centering
        \includegraphics[width=0.85\textwidth]{imgs/predicciones_futuro.png}
        \caption{Predicciones a futuro} \label{fig:predicciones_futuro}
    \end{figure}
\end{center}

A modo de conclusión, tenemos un modelo \texttt{ARIMA$(0,1,1)(0,1,1)_{12}$} que hemos creado de forma manual, que hemos determinado que era el ganador, por ser 
el que mejor parsimonia y ajuste tiene en cuanto a los datos. Tras realizar las predicciones, además, se observan unos resultados bastante bien ajustados. Los 
residuos del modelo pueden considerarse ruido blanco, lo que indica también que el modelo ha capturado correcatmente las dependencias temporales. Además, son 
estables, por lo que el modelo no estaría sesgado. Las métricas de AIC y BIC obtenidas apoyan esto, ya que sugieren que el modelo no está sobreajustado y que no 
es excesivamente complejo. Las predicciones que realiza son adecuadas a corto plazo, pero una posible mejora para este ejercicio podría ser probar con otro tipo 
de modelos, o incorporar algunas variables que se sepa que afectan especialmente al número de viajeros, para poder realizar mejores predicciones a largo plazo.

\clearpage
\newpage

\appendix
\section{Anexo: Código de la práctica}\label{anexo1}
\lstinputlisting[language=Python]{codigoMineria3.py}
\end{sloppypar}
\end{document}
